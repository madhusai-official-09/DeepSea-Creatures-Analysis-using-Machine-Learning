{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "           Species Name Migration Type  Water Temperature (Â°C)  \\\n",
      "0         Doomsday Fish       Atypical                      10   \n",
      "1            Anglerfish        Typical                       5   \n",
      "2  Southern Right Whale       Atypical                      15   \n",
      "3   Olive Ridley Turtle       Atypical                      25   \n",
      "4    Blackspot Seabream       Seasonal                      12   \n",
      "\n",
      "   Salinity (ppt)        Sighting Location Sighting Date    IUCN Status  \n",
      "0              35        Offshore Tasmania    2023-02-15     Not Listed  \n",
      "1              32       Deep Sea, Atlantic    2022-08-20     Not Listed  \n",
      "2              33  Adventure Bay, Tasmania    2023-06-01     Endangered  \n",
      "3              30      Unexpected Location    2023-09-10     Vulnerable  \n",
      "4              34    Seamount, NE Atlantic    2022-04-01  Least Concern  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"deepsea.csv\")\n",
    "\n",
    "# Display the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define the RL environment\n",
    "class MigrationEnvironment:\n",
    "    def __init__(self, temperature_range, salinity_range):\n",
    "        self.temperature_range = temperature_range\n",
    "        self.salinity_range = salinity_range\n",
    "        self.state = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Start with a random state (temperature, salinity)\n",
    "        self.state = (\n",
    "            np.random.uniform(self.temperature_range[0], self.temperature_range[1]),\n",
    "            np.random.uniform(self.salinity_range[0], self.salinity_range[1])\n",
    "        )\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulate the effect of an action on the environment\n",
    "        temperature, salinity = self.state\n",
    "\n",
    "        # Action 0: Move to colder water\n",
    "        # Action 1: Move to warmer water\n",
    "        # Action 2: Move to higher salinity\n",
    "        # Action 3: Move to lower salinity\n",
    "        if action == 0:\n",
    "            temperature = max(temperature - 1, self.temperature_range[0])\n",
    "        elif action == 1:\n",
    "            temperature = min(temperature + 1, self.temperature_range[1])\n",
    "        elif action == 2:\n",
    "            salinity = min(salinity + 1, self.salinity_range[1])\n",
    "        elif action == 3:\n",
    "            salinity = max(salinity - 1, self.salinity_range[0])\n",
    "\n",
    "        self.state = (temperature, salinity)\n",
    "\n",
    "        # Calculate reward (simplified: species prefers specific conditions)\n",
    "        target_temperature = 15  # Example target temperature\n",
    "        target_salinity = 33    # Example target salinity\n",
    "        reward = -abs(temperature - target_temperature) - abs(salinity - target_salinity)\n",
    "\n",
    "        done = False  # The episode never ends in this simplified example\n",
    "        return self.state, reward, done\n",
    "\n",
    "# Define the Q-Learning agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, env, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
    "        self.env = env\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Initialize Q-table\n",
    "        self.q_table = np.zeros((100, 100, 4))  # Grid for temperature, salinity, and 4 actions\n",
    "\n",
    "    def discretize_state(self, state):\n",
    "        # Discretize continuous state (temperature, salinity) into grid indices\n",
    "        temperature, salinity = state\n",
    "        temp_index = int((temperature - self.env.temperature_range[0]) / (self.env.temperature_range[1] - self.env.temperature_range[0]) * 99)\n",
    "        salinity_index = int((salinity - self.env.salinity_range[0]) / (self.env.salinity_range[1] - self.env.salinity_range[0]) * 99)\n",
    "        return temp_index, salinity_index\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        # Epsilon-greedy policy\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.choice(4)  # Random action\n",
    "        else:\n",
    "            temp_index, salinity_index = self.discretize_state(state)\n",
    "            return np.argmax(self.q_table[temp_index, salinity_index])\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        # Update Q-value using the Bellman equation\n",
    "        temp_index, salinity_index = self.discretize_state(state)\n",
    "        next_temp_index, next_salinity_index = self.discretize_state(next_state)\n",
    "\n",
    "        current_q = self.q_table[temp_index, salinity_index, action]\n",
    "        max_future_q = np.max(self.q_table[next_temp_index, next_salinity_index])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_future_q - current_q)\n",
    "\n",
    "        self.q_table[temp_index, salinity_index, action] = new_q\n",
    "\n",
    "# Initialize environment and agent\n",
    "env = MigrationEnvironment(temperature_range=(0, 30), salinity_range=(30, 35))\n",
    "agent = QLearningAgent(env)\n",
    "\n",
    "# Train the agent\n",
    "episodes = 1000\n",
    "rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        agent.update_q_table(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "# Plot training progress\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Q-Learning Training Progress\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the agent\n",
    "test_episodes = 10\n",
    "test_rewards = []\n",
    "\n",
    "for episode in range(test_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    test_rewards.append(total_reward)\n",
    "\n",
    "print(\"Average Test Reward:\", np.mean(test_rewards))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
